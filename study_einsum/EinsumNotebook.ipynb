{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Understand einstem summation in numpy\n",
    "\n",
    "Start with https://obilaniu6266h16.wordpress.com/2016/02/04/einstein-summation-in-numpy/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example1:  of is a classic matrix mulitplication\n",
    "# C = A * B\n",
    "N_i = 2\n",
    "N_k = 3\n",
    "N_j = 4\n",
    "A = np.random.rand(N_i, N_k)\n",
    "B = np.random.rand(N_k, N_j)\n",
    "\n",
    "## Method 1. Classic matrix multiplication\n",
    "C = np.empty((N_i, N_j))\n",
    "for i in range(N_i): # i and j are called free indices\n",
    "    for j in range(N_j):\n",
    "        total = 0\n",
    "        for k in range(N_k): # k is called a summation index\n",
    "            total += A[i,k] * B[k,j]\n",
    "        C[i,j] = total\n",
    "\n",
    "assert np.allclose(C, np.dot(A, B))\n",
    "\n",
    "## Method 2. Einstein summation\n",
    "C = np.einsum(\"ik, kj -> ij\", A, B)\n",
    "assert np.allclose(C, np.dot(A, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example2: extracting matrix diagonal of a square matrix\n",
    "N = 5\n",
    "A = np.random.rand(N, N)\n",
    "d = np.empty(N)\n",
    "\n",
    "## Method 1. Classic matrix diagonal extraction\n",
    "for i in range(N): # free index i\n",
    "    total = 0\n",
    "    total += A[i,i] # summation index: None\n",
    "    d[i] = total\n",
    "\n",
    "assert np.allclose(d, np.diag(A))\n",
    "\n",
    "## Method 2. Einstein summation\n",
    "d = np.einsum(\"ii -> i\", A)\n",
    "assert np.allclose(d, np.diag(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example3: Matrix trace\n",
    "N = 5\n",
    "A = np.random.rand(N, N)\n",
    "\n",
    "## Method 1. Classic matrix trace\n",
    "total = 0\n",
    "for i in range(N): # free index: None\n",
    "    total += A[i][i] # summation index: i\n",
    "\n",
    "assert np.allclose(total, np.trace(A))\n",
    "\n",
    "## Method 2. Einsum notation\n",
    "total = np.einsum(\"ii->\", A)\n",
    "assert np.allclose(total, np.trace(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example4: Quadratic form v^T @ A @ v\n",
    "N = 5\n",
    "v = np.random.rand(N)\n",
    "A = np.random.rand(N,N)\n",
    "\n",
    "## Method 1. Classic\n",
    "out_sum = 0\n",
    "for i in range(N): # free index: None\n",
    "    total = 0\n",
    "    for k in range(N): # summation index: i, k\n",
    "        total += v[k] * A[k,i]\n",
    "\n",
    "    out_sum += total * v[i]\n",
    "\n",
    "assert np.allclose(out_sum, v.T @ A @ v)\n",
    "\n",
    "## Method 2. einsum\n",
    "out_sum = np.einsum(\"i,ij,j -> \", v.T, A, v)\n",
    "assert np.allclose(out_sum, v.T @ A @ v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 5: Outer product of 2 vectors\n",
    "Ni = 3\n",
    "Nj = 5\n",
    "v = np.random.rand(Ni)\n",
    "z = np.random.rand(Nj)\n",
    "\n",
    "## Method 1: v @ zT\n",
    "A = np.empty((Ni, Nj))\n",
    "for i in range(Ni):\n",
    "    for j in range(Nj):\n",
    "        A[i, j] = v[i] * z[j]\n",
    "\n",
    "assert np.allclose(A, v.reshape(Ni,1) @ z.reshape(1, Nj))\n",
    "\n",
    "## Method 2: einsum\n",
    "A = np.einsum(\"i,j->ij\", v, z)\n",
    "assert np.allclose(A,  v.reshape(Ni,1) @ z.reshape(1, Nj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 6: Batched Outer product of 2 matrix\n",
    "Batch = 3\n",
    "Ni = 4\n",
    "Nj = 5\n",
    "\n",
    "A = np.random.rand(Batch, Ni)\n",
    "B = np.random.rand(Batch, Nj)\n",
    "\n",
    "# Method1 : class\n",
    "C = np.empty((Batch, Ni, Nj))\n",
    "for i in range(Batch): # i j k are all free indices\n",
    "    for j in range(Ni):\n",
    "        for k in range(Nj):\n",
    "            C[i,j,k] = A[i,j] * B[i,k] # No summation index as we do not remove any index\n",
    "\n",
    "# Method 2 : einsum\n",
    "D = np.einsum(\"ij,ik->ijk\", A, B)\n",
    "\n",
    "assert np.allclose(C, D)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Reading introduction to numpy's einsum is really good as it has 3 concises points perfectly\n",
    "https://ajcr.net/Basic-guide-to-einsum/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Einsum follow Tim rock\n",
    "https://rockt.github.io/2018/04/30/einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix transpose\n",
    "A = torch.arange(6).reshape(2,3)\n",
    "\n",
    "print(A)\n",
    "B = torch.einsum('ij->ji', A)\n",
    "print(B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "tensor(15)\n"
     ]
    }
   ],
   "source": [
    "# Sum\n",
    "A = torch.arange(6).reshape(2,3)\n",
    "print(A)\n",
    "B = torch.einsum('ij->', A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "tensor([3, 5, 7])\n"
     ]
    }
   ],
   "source": [
    "# Column sum\n",
    "A = torch.arange(6).reshape(2,3)\n",
    "print(A)\n",
    "B = torch.einsum('ij->j', A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "# Dot product\n",
    "a = torch.arange(3)\n",
    "b = torch.arange(3)\n",
    "c = torch.einsum('i,i->', a, b)\n",
    "print(c)\n",
    "\n",
    "# However, below expression is only doing sum each axis and multiply\n",
    "# this is because different letter, thus they are not multiplied. But after finishing,\n",
    "# they will be multiplied\n",
    "c = torch.einsum('i,j->', a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0],\n",
      "        [0, 1, 2, 3, 4],\n",
      "        [0, 2, 4, 6, 8]])\n"
     ]
    }
   ],
   "source": [
    "# Outer product\n",
    "a = torch.arange(3)\n",
    "b = torch.arange(5)\n",
    "c = torch.einsum('i,j->ij', a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  4],\n",
      "        [ 9, 16, 25]])\n"
     ]
    }
   ],
   "source": [
    "# Hadamard product\n",
    "a = torch.arange(6).reshape(2,3)\n",
    "b = torch.arange(6).reshape(2,3)\n",
    "c = torch.einsum('ij,ij->ij', a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.5276],\n",
      "        [ 0.2850],\n",
      "        [-0.7522]])\n"
     ]
    }
   ],
   "source": [
    "# Bilinear transformation\n",
    "a = torch.randn(3,5)\n",
    "b = torch.randn(1,5,6)\n",
    "c = torch.randn(3,6)\n",
    "\n",
    "d = torch.einsum('ik,jkl,il->ij', a,b,c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
